{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a6d5f55-0767-4e2d-b6e5-60c42d024dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import classification_report\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c8b94de-78c6-4153-9803-4743ba2f5cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"Babelscape/wikineural-multilingual-ner\"\n",
    "# model_name = \"\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3fa4850-0346-4410-a716-82132d621367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed French dataset\n",
    "from datasets import load_from_disk\n",
    "french_dataset = load_from_disk(\"Data/Data_fr/test_fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "407e7fb5-60ac-464a-b2fb-ce92a26d8c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['Upton', 'Park', 'exempt'], 'ner_tags': [0, 0, 3, 4, 0, 0, 0, 0, 0], 'langs': ['fr', 'fr', 'fr', 'fr', 'fr', 'fr', 'fr', 'fr', 'fr'], 'spans': ['ORG: Upton Park'], 'input_ids': [101, 13656, 11183, 11239, 11419, 10451, 14971, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, 0, -100, 0, 3, -100, -100, -100]}\n",
      "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None), 'langs': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'spans': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "print(french_dataset[0])  # Print the first example\n",
    "print(french_dataset.features)  # Print the dataset features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26a720ed-f3f4-4e62-83bc-4a53d63d2367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(examples):\n",
    "    # The tokenization step is not needed as input_ids are already present\n",
    "    return {\n",
    "        'input_ids': examples['input_ids'],\n",
    "        'attention_mask': examples['attention_mask'],\n",
    "        'token_type_ids': examples['token_type_ids'],\n",
    "        'labels': examples['labels']\n",
    "    }\n",
    "\n",
    "tokenized_french = french_dataset.map(prepare_dataset, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc16a5a5-323c-425e-bc13-f75f88a9e82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data loader:\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'input_ids': torch.tensor([item['input_ids'] for item in batch]),\n",
    "        'attention_mask': torch.tensor([item['attention_mask'] for item in batch]),\n",
    "        'token_type_ids': torch.tensor([item['token_type_ids'] for item in batch]),\n",
    "        'labels': torch.tensor([item['labels'] for item in batch])\n",
    "    }\n",
    "\n",
    "data_loader = DataLoader(tokenized_french, batch_size=16, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d5cc0a8-17e7-44f3-b4d2-792928694379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = [torch.tensor(item['input_ids']) for item in batch]\n",
    "    attention_mask = [torch.tensor(item['attention_mask']) for item in batch]\n",
    "    token_type_ids = [torch.tensor(item['token_type_ids']) for item in batch]\n",
    "    labels = [torch.tensor(item['labels']) for item in batch]\n",
    "    \n",
    "    # Pad sequences to the maximum length in the batch\n",
    "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
    "    attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "    token_type_ids = pad_sequence(token_type_ids, batch_first=True, padding_value=0)\n",
    "    labels = pad_sequence(labels, batch_first=True, padding_value=-100)  # Use -100 for padding in labels\n",
    "    \n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'token_type_ids': token_type_ids,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "data_loader = DataLoader(tokenized_french, batch_size=16, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "965e001e-b5fb-4c31-96c8-4da29e2900f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 625/625 [01:10<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.14      0.16      0.15      4640\n",
      "         ORG       0.18      0.07      0.10      5089\n",
      "         PER       0.12      0.13      0.13      4714\n",
      "\n",
      "   micro avg       0.14      0.12      0.13     14443\n",
      "   macro avg       0.15      0.12      0.13     14443\n",
      "weighted avg       0.15      0.12      0.13     14443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from seqeval.metrics import classification_report\n",
    "\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_true_labels = []\n",
    "\n",
    "label_map = {0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-LOC', 6: 'I-LOC'}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "        inputs = {k: v.to(model.device) for k, v in batch.items() if k != 'labels'}\n",
    "        labels = batch['labels'].to(model.device)\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=2)\n",
    "        \n",
    "        for pred, label, mask in zip(predictions, labels, batch['attention_mask']):\n",
    "            pred = pred.cpu().numpy()\n",
    "            label = label.cpu().numpy()\n",
    "            mask = mask.cpu().numpy()\n",
    "            \n",
    "            true_label = [label_map.get(l.item(), 'O') for l, m in zip(label, mask) if m != 0]\n",
    "            pred_label = [label_map.get(p.item(), 'O') for p, m in zip(pred, mask) if m != 0]\n",
    "            \n",
    "            # Ensure both lists have the same length\n",
    "            min_len = min(len(true_label), len(pred_label))\n",
    "            true_label = true_label[:min_len]\n",
    "            pred_label = pred_label[:min_len]\n",
    "            \n",
    "            all_predictions.append(pred_label)\n",
    "            all_true_labels.append(true_label)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(all_true_labels, all_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0e8a4e-320d-4f64-8de9-6ba6af5fd724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
