{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a6d5f55-0767-4e2d-b6e5-60c42d024dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import classification_report\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c8b94de-78c6-4153-9803-4743ba2f5cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"./finetuned_wikineural\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3fa4850-0346-4410-a716-82132d621367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed French dataset\n",
    "from datasets import load_from_disk\n",
    "italian_dataset = load_from_disk(\"Data_it/test_it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "407e7fb5-60ac-464a-b2fb-ce92a26d8c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['Washington', 'Mystics'], 'ner_tags': [0, 0, 3, 4, 0, 0], 'langs': ['it', 'it', 'it', 'it', 'it', 'it'], 'spans': ['ORG: Washington Mystics'], 'input_ids': [101, 11586, 110760, 10107, 102], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1], 'labels': [-100, 0, 0, -100, -100]}\n",
      "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None), 'langs': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'spans': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "print(italian_dataset[0])  # Print the first example\n",
    "print(italian_dataset.features)  # Print the dataset features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26a720ed-f3f4-4e62-83bc-4a53d63d2367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66cae2af7ca74b488183bea60c62de28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepare_dataset(examples):\n",
    "    # The tokenization step is not needed as input_ids are already present\n",
    "    return {\n",
    "        'input_ids': examples['input_ids'],\n",
    "        'attention_mask': examples['attention_mask'],\n",
    "        'token_type_ids': examples['token_type_ids'],\n",
    "        'labels': examples['labels']\n",
    "    }\n",
    "\n",
    "tokenized_italian = italian_dataset.map(prepare_dataset, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc16a5a5-323c-425e-bc13-f75f88a9e82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data loader:\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'input_ids': torch.tensor([item['input_ids'] for item in batch]),\n",
    "        'attention_mask': torch.tensor([item['attention_mask'] for item in batch]),\n",
    "        'token_type_ids': torch.tensor([item['token_type_ids'] for item in batch]),\n",
    "        'labels': torch.tensor([item['labels'] for item in batch])\n",
    "    }\n",
    "\n",
    "data_loader = DataLoader(tokenized_italian, batch_size=16, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d5cc0a8-17e7-44f3-b4d2-792928694379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = [torch.tensor(item['input_ids']) for item in batch]\n",
    "    attention_mask = [torch.tensor(item['attention_mask']) for item in batch]\n",
    "    token_type_ids = [torch.tensor(item['token_type_ids']) for item in batch]\n",
    "    labels = [torch.tensor(item['labels']) for item in batch]\n",
    "    \n",
    "    # Pad sequences to the maximum length in the batch\n",
    "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
    "    attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "    token_type_ids = pad_sequence(token_type_ids, batch_first=True, padding_value=0)\n",
    "    labels = pad_sequence(labels, batch_first=True, padding_value=-100)  # Use -100 for padding in labels\n",
    "    \n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'token_type_ids': token_type_ids,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "data_loader = DataLoader(tokenized_italian, batch_size=16, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7594bca1-7a7e-406c-af12-13f3e8bcff00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 625/625 [01:16<00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.18      0.19      0.19      4357\n",
      "         ORG       0.17      0.16      0.17      5128\n",
      "         PER       0.19      0.18      0.18      5094\n",
      "\n",
      "   micro avg       0.18      0.18      0.18     14579\n",
      "   macro avg       0.18      0.18      0.18     14579\n",
      "weighted avg       0.18      0.18      0.18     14579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from seqeval.metrics import classification_report\n",
    "import torch\n",
    "\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_true_labels = []\n",
    "\n",
    "label_map = {0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-LOC', 6: 'I-LOC'}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "        # Überprüfe, ob alle Keys vorhanden sind\n",
    "        assert 'input_ids' in batch and 'attention_mask' in batch and 'labels' in batch, \\\n",
    "            \"Batch fehlt erforderliche Schlüssel!\"\n",
    "\n",
    "        # Inputs und Labels in das richtige Device laden\n",
    "        inputs = {k: v.to(model.device) for k, v in batch.items() if k != 'labels'}\n",
    "        labels = batch['labels'].to(model.device)\n",
    "        \n",
    "        # Vorhersagen generieren\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=2)\n",
    "        \n",
    "        # Labels und Vorhersagen verarbeiten\n",
    "        for pred, label, mask in zip(predictions, labels, batch['attention_mask']):\n",
    "            pred = pred.cpu().numpy()\n",
    "            label = label.cpu().numpy()\n",
    "            mask = mask.cpu().numpy()\n",
    "\n",
    "            # Filtern mit der attention_mask\n",
    "            true_label = [label_map.get(l, 'O') for l, m in zip(label, mask) if m != 0]\n",
    "            pred_label = [label_map.get(p, 'O') for p, m in zip(pred, mask) if m != 0]\n",
    "            \n",
    "            # Listenlänge angleichen (falls nötig)\n",
    "            if len(true_label) != len(pred_label):\n",
    "                min_len = min(len(true_label), len(pred_label))\n",
    "                true_label = true_label[:min_len]\n",
    "                pred_label = pred_label[:min_len]\n",
    "            \n",
    "            all_predictions.append(pred_label)\n",
    "            all_true_labels.append(true_label)\n",
    "\n",
    "# Klassifikationsbericht ausgeben\n",
    "print(classification_report(all_true_labels, all_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0e8a4e-320d-4f64-8de9-6ba6af5fd724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
